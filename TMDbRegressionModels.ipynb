{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Resilient Distributed Datasets (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/regression-models/Movie_TMDb/tmdb-movies-final-features-no-header.csv\"\n",
    "raw_data = sc.textFile(path)\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x: x.split(\",\"))\n",
    "first = records.first()\n",
    "print('First record: ', first)\n",
    "print('Total number of records: ', num_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract each categorical feature into a binary vector form, \n",
    "# we will need to know the feature mapping of each feature value to the index of the nonzero value \n",
    "# in our binary vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings(rdd, idx):\n",
    "    print('index:', idx)\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two categorical features\n",
    "# 1. genres, is at index : 0\n",
    "# 2. release_year is at index :  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping of first categorical feasture column: %s\" % get_mappings(records, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Mapping function to each categorical column (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = [get_mappings(records, i) for i in range(0,2)]\n",
    "\n",
    "cat_len = sum([len(b) for b in mappings])\n",
    "num_len = len(records.first()[2:8])\n",
    "total_len = num_len + cat_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the mappings for each variable, \n",
    "# and we can see how many values in total we need for our binary vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature vector length for categorical features: %d\" % cat_len)\n",
    "print(\"Feature vector length for numerical features: %d\" % num_len)\n",
    "print(\"Total feature vector length: %d\" % total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to use our extracted mappings to convert the categorical features to binary-encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(record):\n",
    "    cat_vec = np.zeros(cat_len)\n",
    "    i = 0\n",
    "    step = 0\n",
    "    for field in record[0:1]: # catogorical feature\n",
    "        print('extract_features', i)\n",
    "        m = mappings[i]\n",
    "        idx = m[field]\n",
    "        cat_vec[idx + step] = 1\n",
    "        i = i + 1\n",
    "        step = step + len(m)\n",
    "    num_vec = np.array([float(field) for field in record[1:7]])\n",
    "    return np.concatenate((cat_vec, num_vec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The extract_label function simply converts the last column variable (Revenue) into a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(record):\n",
    "    return float(record[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.1 Decision Tree #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree models typically work on raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_dt(record):\n",
    "    return np.array(map(float, record[0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Data so that we are ready for training and prediction on Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dt = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Label and Feature Vector from the Dataset \n",
    "# 2.1.1 Decision Tree Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point_dt = data_dt.first()\n",
    "print(\"Raw data: \" + str(first[2:]))\n",
    "print(\"Decision Tree Label: \" + str(first_point_dt.label))\n",
    "print(\"Decision Tree feature vector: \" + str(first_point_dt.features))\n",
    "print(\"Decision Tree feature vector length: \" + str(len(first_point_dt.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData_dt, testData_dt) = data_dt.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTree.trainRegressor(trainingData_dt, categoricalFeaturesInfo={},\n",
    "                                    impurity='variance', maxDepth=5, maxBins=3000)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions_dt = model_dt.predict(testData_dt.map(lambda x: x.features))\n",
    "labelsAndPredictions_dt = testData_dt.map(lambda lp: lp.label).zip(predictions_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_model = DecisionTree.trainRegressor(data_dt,{})\n",
    "# preds = dt_model.predict(data_dt.map(lambda p: p.features))\n",
    "# actual = data.map(lambda p: p.label)\n",
    "# true_vs_predicted_dt = actual.zip(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learned regression tree model:')\n",
    "print(model_dt.toDebugString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Suarred Error\n",
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2\n",
    "\n",
    "# Aboslute Error\n",
    "def abs_error(actual, pred):\n",
    "     return np.abs(pred - actual)\n",
    "# Mean Squared Error     \n",
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2) Decision Tree Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testMSE_dt = labelsAndPredictions_dt.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() / float(testData.count())\n",
    "\n",
    "rmsle_dt = np.sqrt(labelsAndPredictions_dt.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse = labelsAndPredictions_dt.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae = labelsAndPredictions_dt.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Model - Root Mean Squared Log Error: %2.4f\" % rmsle_dt)\n",
    "print(\"Decision Tree Model - Mean Squared Error: %2.4f\" % mse)\n",
    "print(\"Decision Tree Model - Mean Absolute Error: %2.4f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = records.map(lambda r: float(r[-1])).collect()\n",
    "hist(targets, bins=20, color='lightblue', normed=True)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3) Decision Tree Max Bins\n",
    "# 2.14) Decision Tree Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (RMSLE vs MaxDepth) and (RMSLE vs MaxBins) evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dt(trainData, testData, maxDepthValue, maxBinsValue):\n",
    "    modelDT = DecisionTree.trainRegressor(trainData, categoricalFeaturesInfo={},\n",
    "                                    impurity='variance', maxDepth=maxDepthValue, maxBins=maxBinsValue)\n",
    "\n",
    "    # Evaluate model on test instances and compute test error\n",
    "    predits = modelDT.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredicts = testData.map(lambda lp: lp.label).zip(predits)\n",
    "    rmsleDT = np.sqrt(labelsAndPredicts.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsleDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3) Decision Tree Max Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constantMaxDepthAndBinsParams = [32, 64, 80, 100, 200, 400]\n",
    "\n",
    "metrics = [evaluate_dt(trainingData_dt, testData_dt, 5, param) # constant Max Depth\n",
    "           for param in constantMaxDepthAndBinsParams]\n",
    "print(constantMaxDepthAndBinsParams)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting : Decision Tree Max Bins\n",
    "plot(constantMaxDepthAndBinsParams, metrics)\n",
    "plt.xlabel('Max Bins')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.4) Decision Tree Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepthAndConstantBinsParams = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "metricsMaxDepth = [evaluate_dt(trainingData_dt, testData_dt, param, 150) \n",
    "           for param in maxDepthAndConstantBinsParams]\n",
    "print(maxDepthAndConstantBinsParams)\n",
    "print(metricsMaxDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting : Decision Tree Max Depth\n",
    "plot(maxDepthAndConstantBinsParams, metricsMaxDepth)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Gradient boost tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a GradientBoostedTrees model.\n",
    "#  Notes: (a) Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "#         (b) Use more iterations in practice.\n",
    "\n",
    "model_GBT = GradientBoostedTrees.trainRegressor(trainingData_dt,\n",
    "                                            categoricalFeaturesInfo={}, numIterations=3, maxDepth=5, maxBins=64)\n",
    "\n",
    "predictions_GBT = model_GBT.predict(testData_dt.map(lambda x: x.features))\n",
    "labelsAndPredictions_GBT = testData_dt.map(lambda lp: lp.label).zip(predictions_GBT)\n",
    "\n",
    "print('Learned regression Gradient boosted tree lmodel:')\n",
    "print(model_GBT.toDebugString())\n",
    "\n",
    "rmsle_gbt = np.sqrt(labelsAndPredictions_GBT.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse_gbt = labelsAndPredictions_GBT.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae_gbt = labelsAndPredictions_GBT.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "\n",
    "print(\"GradientBoostedTrees Model - Root Mean Squared Log Error: %2.4f\" % rmsle_gbt)\n",
    "print(\"GradientBoostedTrees Model - Mean Squared Error: %2.4f\" % mse_gbt)\n",
    "print(\"GradientBoostedTrees Model - Mean Absolute Error: %2.4f\" % mae_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1) Gradient boost tree iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gbt(trainData, testData, numIterationsValue, maxDepthValue, maxBinsValue):\n",
    "    model_GBT = GradientBoostedTrees.trainRegressor(trainData,\n",
    "                                            categoricalFeaturesInfo={}, numIterations=numIterationsValue,\n",
    "                                                    maxDepth=maxDepthValue, maxBins=maxBinsValue)\n",
    "\n",
    "    predictions_GBT = model_GBT.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredictions_GBT = testData.map(lambda lp: lp.label).zip(predictions_GBT)\n",
    "    rmsleGBT = np.sqrt(labelsAndPredictions_GBT.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsleGBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numInterationsParams = [2, 3, 4]\n",
    "\n",
    "metrics_gbt_iterations = [evaluate_gbt(trainingData_dt, testData_dt, param, 5, 32)\n",
    "           for param in numInterationsParams]\n",
    "print(numInterationsParams)\n",
    "print(metrics_gbt_iterations)\n",
    "\n",
    "# Plotting\n",
    "plot(numInterationsParams, metrics_gbt_iterations)\n",
    "plt.xlabel('Iterations log scale')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2) Gradient boost tree Max Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxBinsParams = [32, 64, 100]\n",
    "\n",
    "metrics_gbt_maxBins = [evaluate_gbt(trainingData_dt, testData_dt, 3, 5, param)\n",
    "           for param in maxBinsParams]\n",
    "print(maxBinsParams)\n",
    "print(metrics_gbt_maxBins)\n",
    "\n",
    "# Plotting : Decision Tree Max Depth\n",
    "plot(maxBinsParams, metrics_gbt_maxBins)\n",
    "plt.xlabel('Max Bins')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.3) Gradient boost tree Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepthParams = [4, 5, 6]\n",
    "\n",
    "metrics_gbt_maxDepth = [evaluate_gbt(trainingData_dt, testData_dt, 3, param, 32)\n",
    "           for param in maxDepthParams]\n",
    "print(maxDepthParams)\n",
    "print(metrics_gbt_maxDepth)\n",
    "\n",
    "# Plotting\n",
    "plot(maxDepthParams, metrics_gbt_maxDepth)\n",
    "plt.xlabel('Max Depths')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3. Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can proceed with extracting feature vectors and labels from our data records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_linear = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the first record in the extracted feature RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point = data_linear.first()\n",
    "print(\"Raw data: \" + str(first[2:]))\n",
    "print(\"Label: \" + str(first_point.label))\n",
    "print(\"Linear Model feature vector:\\n\" + str(first_point.features))\n",
    "print(\"Linear Model feature vector length: \" + str(len(first_point.\n",
    "features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData_linear, testData_linear) = data_linear.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LinearRegressionWithSGD.train(trainingData_linear, iterations=5, step=0.01)\n",
    "# Building a Regression Model with Spark\n",
    "true_vs_predicted_LR = testData_linear.map(lambda p: (p.label, model_LR.predict(p.features)))\n",
    "print(\"Linear Model predictions: \" + str(true_vs_predicted_LR.take(5)))\n",
    "\n",
    "\n",
    "predictions_linear = model_LR.predict(testData_linear.map(lambda x: x.features))\n",
    "labelsAndPredictions_linear = testData_linear.map(lambda lp: lp.label).zip(predictions_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.1) Linear regression Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data size', trainingData_linear.count())\n",
    "print('Test data size', testData_linear.count())\n",
    "\n",
    "print('Total data size', trainingData_linear.count() + testData_linear.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train, test, iterations, step, regParam, regType, intercept):\n",
    "    model = LinearRegressionWithSGD.train(train, iterations, step, \n",
    "                                          regParam=regParam, regType=regType, intercept=intercept)\n",
    "    tp = test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    rmsle = np.sqrt(tp.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2.1) Intercept\n",
    "\n",
    "params_intercept = [True, False]\n",
    "metrics_intercept = [evaluate(trainingData_linear, testData_linear, 3, 0.01, 0.0, 'l2', param) for param in params_intercept]\n",
    "\n",
    "print(params_intercept)\n",
    "print(metrics_intercept)\n",
    "\n",
    "# Plotting\n",
    "plot(params_intercept, metrics_intercept)\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2.2) Iterations\n",
    "\n",
    "params_iterations = [1, 3, 6]\n",
    "metrics_iterations = [evaluate(trainingData_linear, testData_linear, param, 0.01, 0.0, 'l2', False) for param in params_iterations]\n",
    "\n",
    "print(params_iterations)\n",
    "print(metrics_iterations)\n",
    "\n",
    "# Plotting\n",
    "plot(params_iterations, metrics_iterations)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2.3) Step size\n",
    "\n",
    "params_step = [0.01, 0.025, 0.05, 0.1, 1.0]\n",
    "metrics_step = [evaluate(trainingData_linear, testData_linear, 3, param, 0.0, 'l2', False) for param in params_step]\n",
    "\n",
    "print(params_step)\n",
    "print(metrics_step)\n",
    "\n",
    "# Plotting\n",
    "plot(params_step, metrics_step)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2.4) L1 Regularization\n",
    "\n",
    "params_l1 = params = [0.0, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "metrics_l1 = [evaluate(trainingData_linear, testData_linear, 3, 0.01, param, 'l1', False) for param in params_l1]\n",
    "\n",
    "print(params_l1)\n",
    "print(metrics_l1)\n",
    "\n",
    "# Plotting\n",
    "plot(params_l1, metrics_l1)\n",
    "plt.xlabel('L1 Regularization')\n",
    "plt.ylabel('RMSLE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2.4) L2 Regularization\n",
    "\n",
    "params_l2 = params = [0.0, 0.01, 0.1, 1.0, 5.0, 10.0]\n",
    "metrics_l2 = [evaluate(trainingData_linear, testData_linear, 5, 0.01, param, 'l2', False) for param in params_l2]\n",
    "\n",
    "print(params_l2)\n",
    "print(metrics_l2)\n",
    "\n",
    "# Plotting\n",
    "plot(params_l2, metrics_l2)\n",
    "plt.xlabel('L2 Regularization')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.3) Linear regression Log\n",
    "\n",
    "rmsle_lr = np.sqrt(labelsAndPredictions_linear.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse_lr = labelsAndPredictions_linear.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae_lr = labelsAndPredictions_linear.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "\n",
    "print(\"LinearRegression Root Mean Squared Log Error: %2.4f\" % rmsle_lr)\n",
    "print(\"LinearRegression - Mean Squared Error: %2.4f\" % mse_lr)\n",
    "print(\"LinearRegression - Mean Absolute Error: %2.4f\" % mae_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
